{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc933688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "import pprint\n",
    "\n",
    "import multiprocessing as mp\n",
    "import concurrent\n",
    "import time\n",
    "tstamp = time.perf_counter_ns()\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7501222f",
   "metadata": {},
   "source": [
    "# build pub\n",
    "\n",
    "- minimal PWM5 task:\n",
    "    - 5 stimuli (ABCDE) \n",
    "    - 3 trials of trlen 3\n",
    "    - with violation timeout \n",
    "    \n",
    "## validating pub \n",
    "\n",
    "- first step will be to train with pub but without invalid trials \n",
    "- not sure what the right gamma will be\n",
    "    - when gamma=1.0, there is no incentive to not violate trials. \n",
    "\n",
    "## todo\n",
    "- setup flag_args for `pub` and `vto` \"violation timeout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01d2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_exp(seed,args):\n",
    "  \"\"\" loss [(value, policy),neps] \"\"\"\n",
    "  # setup\n",
    "  np.random.seed(seed)\n",
    "  neps = args['train']['neps']\n",
    "  # task and agent definition\n",
    "  agent = ActorCritic(**args['agent'])\n",
    "  task = PWMTaskFR(**args['task'])\n",
    "  # init loop vars\n",
    "  reward = -np.ones(neps)\n",
    "  loss = -np.ones([2,neps])\n",
    "  pism = -np.ones([3,neps])\n",
    "  trcount = -np.ones(neps)\n",
    "  L = []\n",
    "  # loop over epochs\n",
    "  for epoch in range(neps):\n",
    "    epoch_data = run_epoch_FR(agent,task,pub=True)\n",
    "    epoch_data = process_epdata(epoch_data)\n",
    "    update_data = agent.update(epoch_data)\n",
    "    trcount[epoch] = np.sum(epoch_data['ttype'])\n",
    "    reward[epoch] = np.sum(epoch_data['reward'])/task.ntrials\n",
    "    loss[:,epoch] = list(update_data.values())\n",
    "  data = {'loss':loss,'reward':reward,'trcount':trcount}\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7bc077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1, 1, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common setup\n",
    "ns,neps = 3,200000\n",
    "args = {\n",
    "  'train':{\n",
    "    'neps':neps\n",
    "  },\n",
    "  'agent':{\n",
    "    'gamma':1.0,\n",
    "    'learnrate':0.005,\n",
    "    'lweight':None # gridsearching\n",
    "  },\n",
    "  'task':{\n",
    "    'stimset':'pwm5',\n",
    "    'epoch_len':9, ## 3 trials len 3 each\n",
    "    'trlen':3\n",
    "  }\n",
    "}\n",
    "\n",
    "# loop vars\n",
    "lwL = [2] ## \n",
    "loss = np.zeros([len(lwL),ns,2,neps])\n",
    "reward = np.zeros([len(lwL),ns,neps])\n",
    "trcount = np.zeros([len(lwL),ns,neps])\n",
    "# gridsearch loss weight\n",
    "for idx in range(len(lwL)):\n",
    "  print('c')\n",
    "  # setup and run exp\n",
    "  args['agent']['lweight'] = lwL[idx]\n",
    "  dataL = exp_mp(seed_exp,nseeds=ns,gsvar=args)\n",
    "  # unpack data\n",
    "  loss[idx] = np.array([d['loss'] for d in dataL])\n",
    "  reward[idx] = np.array([d['reward'] for d in dataL])\n",
    "  trcount[idx] = np.array([d['trcount'] for d in dataL])\n",
    "\n",
    "# reshape data for plotting\n",
    "vloss = loss[:,:,0,:]\n",
    "ploss = loss[:,:,1,:]\n",
    "data = np.array([reward,vloss,ploss])\n",
    "data.shape # [{R/vL/pL},cond,seeds,epochs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b6cb8",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6693a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward\n",
    "for r in reward.mean(1):\n",
    "  plt.plot(r.reshape(-1,10).mean(-1))\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "# trial count\n",
    "for idx in range(len(lwL)): # loop over conds\n",
    "  plt.plot(trcount[idx].mean(0).reshape(-1,20).mean(-1),\n",
    "          label=lwL[idx])\n",
    "plt.ylabel('trial_count')\n",
    "plt.legend()\n",
    "plt.savefig('figures/trial_count-pwm5eplen%i-REINFORCE-lrate_%.4f-%iseeds-gridsearch_lossweight-%i.png'%(\n",
    "  args['task']['epoch_len'],args['agent']['learnrate'],ns,tstamp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_metrics(data,condL,mawin=10):\n",
    "  \"\"\" plot data{reward,vloss,ploss}\n",
    "  input shapes [num_cond,seed,epochs]\n",
    "  moving average to smooth plots\n",
    "  condL labels conds along num_cond\n",
    "  \"\"\"\n",
    "  _,ncond,nseeds,nepochs = data.shape\n",
    "  mdata = data.mean(2)\n",
    "  sdata = data.std(2)/np.sqrt(nseeds)\n",
    "  # plot setup\n",
    "  f,axar = plt.subplots(ncond,3,figsize=(35,6*ncond),sharex=True)\n",
    "  axar[0,0].set_title('reward')\n",
    "  axar[0,1].set_title('value loss')\n",
    "  axar[0,2].set_title('policy loss')\n",
    "  # loop over axes\n",
    "  for ci in range(ncond):\n",
    "    axa = axar[ci]\n",
    "    axa[0].set_ylabel(condL[ci])\n",
    "    axa[0].set_ylim(0.2,1)\n",
    "    for ii in range(3):\n",
    "      ax = axa[ii]\n",
    "      # moving average\n",
    "      M = mdata[ii,ci].reshape(-1,mawin).mean(-1)\n",
    "      S = sdata[ii,ci].reshape(-1,mawin).mean(-1)\n",
    "      ax.plot(M)\n",
    "      ax.fill_between(range(len(M)),M-S,M+S,alpha=0.2)\n",
    "\n",
    "  return None\n",
    "\n",
    "plt_metrics(data,lwL,mawin=10)\n",
    "\n",
    "plt.savefig('figures/loss+reward-pwm5eplen%i-REINFORCE-lrate_%.4f-%iseeds-gridsearch_lossweight-%i.png'%(\n",
    "  args['task']['epoch_len'],args['agent']['learnrate'],ns,tstamp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97a92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
